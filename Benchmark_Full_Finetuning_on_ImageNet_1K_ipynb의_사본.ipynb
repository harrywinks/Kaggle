{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Benchmark Full-Finetuning on ImageNet-1K.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harrywinks/Kaggle/blob/master/Benchmark_Full_Finetuning_on_ImageNet_1K_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9Fa0V1T7AW9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "9867a0ca-dea3-4b40-df14-e6365b31e133"
      },
      "source": [
        "# Copyright (c) Facebook, Inc. and its affiliates. All rights reserved.\n",
        " !pip install torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        " # install opencv\n",
        " !pip install opencv-python\n",
        " !pip install apex -f https://dl.fbaipublicfiles.com/vissl/packaging/apexwheels/{version_str}/download.html "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-16e11311ea28>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    get_ipython().system('pip install torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html')\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XzxTZfKwFNo"
      },
      "source": [
        "# Benchmark Full-Finetuning on ImageNet-1K\n",
        "\n",
        "In this tutorial, we look at a simple example of how to use VISSL to run full finetuning benchmark for [ResNet-50 Torchvision pre-trained model](https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py#L16). This benchmark initializes the model trunk, attaches a linear classification head linear MLP on top of the trunk features and trains the full model.\n",
        "\n",
        "You can make a copy of this tutorial by `File -> Open in playground mode` and make changes there. DO NOT request access to this tutorial.\n",
        "\n",
        "**NOTE:** Please ensure your Collab Notebook has GPU available. To ensure/select this, simple follow: `Edit -> Notebook Settings -> select GPU`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VohdWhBSw69e"
      },
      "source": [
        "## Install VISSL\n",
        "\n",
        "Installing VISSL is pretty straightfoward. We will use pip binaries of VISSL and follow instructions from [here](https://github.com/facebookresearch/vissl/blob/master/INSTALL.md#install-vissl-pip-package)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5ISg59KTOqU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2f7cb1d4-5beb-4fd2-b0e1-c7d0d3aba377"
      },
      "source": [
        "# Install: PyTorch (we assume 1.5.1 but VISSL works with all PyTorch versions >=1.4)\n",
        "!pip install torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# install opencv\n",
        "!pip install opencv-python\n",
        "\n",
        "# install apex by checking system settings: cuda version, pytorch version, python version\n",
        "import sys\n",
        "import torch\n",
        "version_str=\"\".join([\n",
        "    f\"py3{sys.version_info.minor}_cu\",\n",
        "    torch.version.cuda.replace(\".\",\"\"),\n",
        "    f\"_pyt{torch.__version__[0:5:2]}\"\n",
        "])\n",
        "print(version_str)\n",
        "\n",
        "# install apex (pre-compiled with optimizer C++ extensions and CUDA kernels)\n",
        "!pip install apex -f https://dl.fbaipublicfiles.com/vissl/packaging/apexwheels/{version_str}/download.html\n",
        "\n",
        "# install VISSL\n",
        "!pip install vissl"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.5.1+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torch-1.5.1%2Bcu101-cp37-cp37m-linux_x86_64.whl (704.4MB)\n",
            "\u001b[K     |████████████████████████████████| 704.4MB 27kB/s \n",
            "\u001b[?25hCollecting torchvision==0.6.1+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.6.1%2Bcu101-cp37-cp37m-linux_x86_64.whl (6.6MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7MB 45.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.5.1+cu101) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.5.1+cu101) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.6.1+cu101) (7.1.2)\n",
            "\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.5.1+cu101 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.8.1+cu101\n",
            "    Uninstalling torch-1.8.1+cu101:\n",
            "      Successfully uninstalled torch-1.8.1+cu101\n",
            "  Found existing installation: torchvision 0.9.1+cu101\n",
            "    Uninstalling torchvision-0.9.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.9.1+cu101\n",
            "Successfully installed torch-1.5.1+cu101 torchvision-0.6.1+cu101\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.19.5)\n",
            "py37_cu101_pyt151\n",
            "Looking in links: https://dl.fbaipublicfiles.com/vissl/packaging/apexwheels/py37_cu101_pyt151/download.html\n",
            "Collecting apex\n",
            "\u001b[?25l  Downloading https://dl.fbaipublicfiles.com/vissl/packaging/apexwheels/py37_cu101_pyt151/apex-0.1-cp37-cp37m-linux_x86_64.whl (11.4MB)\n",
            "\u001b[K     |████████████████████████████████| 11.4MB 4.1MB/s \n",
            "\u001b[?25hInstalling collected packages: apex\n",
            "Successfully installed apex-0.1\n",
            "Collecting vissl\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/6f/e908efc4ab7e1d2178feb6a86c1d6955526e4f9da4d1d235779125940c04/vissl-0.1.5-py3-none-any.whl (754kB)\n",
            "\u001b[K     |████████████████████████████████| 757kB 8.9MB/s \n",
            "\u001b[?25hCollecting parameterized==0.7.4\n",
            "  Downloading https://files.pythonhosted.org/packages/ba/6b/73dfed0ab5299070cf98451af50130989901f50de41fe85d605437a0210f/parameterized-0.7.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from vissl) (0.22.2.post1)\n",
            "Requirement already satisfied: pycocotools>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from vissl) (2.0.2)\n",
            "Collecting fvcore\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/8b/151130e294de534b8d65f3d92ba19421a80cd430a003437f8246479b5ec1/fvcore-0.1.5.post20210514.tar.gz (48kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from vissl) (1.19.5)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from vissl) (0.8.9)\n",
            "Collecting fairscale\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/55/46/232ab1ab230e1dec3dae1b84bbbbeffef46051adf80bf1cac750dfc94cbe/fairscale-0.3.6.tar.gz (170kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 46.3MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting hydra-core>=1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/e3/fbd70dd0d3ce4d1d75c22d56c0c9f895cfa7ed6587a9ffb821d6812d6a60/hydra_core-1.0.6-py3-none-any.whl (123kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 40.7MB/s \n",
            "\u001b[?25hCollecting tensorboard==1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 35.0MB/s \n",
            "\u001b[?25hCollecting faiss>=1.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ef/2e/dc5697e9ff6f313dcaf3afe5ca39d7d8334114cbabaed069d0026bbc3c61/faiss-1.5.3-cp37-cp37m-manylinux1_x86_64.whl (4.7MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7MB 47.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from vissl) (0.29.23)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->vissl) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->vissl) (1.0.1)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools>=2.0.1->vissl) (3.2.2)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools>=2.0.1->vissl) (56.1.0)\n",
            "Collecting yacs>=0.1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/38/4f/fe9a4d472aa867878ce3bb7efb16654c5d63672b86dc0e6e953a67018433/yacs-0.1.8-py3-none-any.whl\n",
            "Collecting pyyaml>=5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 52.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fvcore->vissl) (4.41.1)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from fvcore->vissl) (1.1.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from fvcore->vissl) (7.1.2)\n",
            "Collecting iopath>=0.1.7\n",
            "  Downloading https://files.pythonhosted.org/packages/21/d0/22104caed16fa41382702fed959f4a9b088b2f905e7a82e4483180a2ec2a/iopath-0.1.8-py3-none-any.whl\n",
            "Collecting torch>=1.6.0\n",
            "  Using cached https://files.pythonhosted.org/packages/56/74/6fc9dee50f7c93d6b7d9644554bdc9692f3023fa5d1de779666e6bf8ae76/torch-1.8.1-cp37-cp37m-manylinux1_x86_64.whl\n",
            "Collecting omegaconf<2.1,>=2.0.5\n",
            "  Downloading https://files.pythonhosted.org/packages/d0/eb/9d63ce09dd8aa85767c65668d5414958ea29648a0eec80a4a7d311ec2684/omegaconf-2.0.6-py3-none-any.whl\n",
            "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from hydra-core>=1.0->vissl) (5.1.2)\n",
            "Collecting antlr4-python3-runtime==4.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/02/789a0bddf9c9b31b14c3e79ec22b9656185a803dc31c15f006f9855ece0d/antlr4-python3-runtime-4.8.tar.gz (112kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 55.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard==1.15.0->vissl) (1.32.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard==1.15.0->vissl) (0.12.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard==1.15.0->vissl) (1.0.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==1.15.0->vissl) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==1.15.0->vissl) (3.12.4)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard==1.15.0->vissl) (0.36.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard==1.15.0->vissl) (3.3.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.1->vissl) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.1->vissl) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.1->vissl) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.1->vissl) (0.10.0)\n",
            "Collecting portalocker\n",
            "  Downloading https://files.pythonhosted.org/packages/68/33/cb524f4de298509927b90aa5ee34767b9a2b93e663cf354b2a3efa2b4acd/portalocker-2.3.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->fairscale->vissl) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-resources; python_version < \"3.9\"->hydra-core>=1.0->vissl) (3.4.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard==1.15.0->vissl) (4.0.1)\n",
            "Building wheels for collected packages: fairscale\n",
            "  Building wheel for fairscale (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairscale: filename=fairscale-0.3.6-cp37-cp37m-linux_x86_64.whl size=1953846 sha256=9ad49ffff6d2b357e342440929c01e54a4086380fda1fc79890ea67354d15d78\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/ad/9a/4208048f3dfd096ce4a947d08131f77e8b618ad34d16abcb06\n",
            "Successfully built fairscale\n",
            "Building wheels for collected packages: fvcore, antlr4-python3-runtime\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20210514-cp37-none-any.whl size=59500 sha256=0fa928d8157cf8d61d05c0f1321c8036c6d2e7b761b4fa4d37b771a72d770e51\n",
            "  Stored in directory: /root/.cache/pip/wheels/32/b3/22/cbb8f617ccbb9d0f8195f23799161d0c21fe6d93607c52220d\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-cp37-none-any.whl size=141231 sha256=6c7c0ddccbdf39d1e508d2d56dd349970f9422668454469b759fe31a01b3d259\n",
            "  Stored in directory: /root/.cache/pip/wheels/e3/e2/fa/b78480b448b8579ddf393bebd3f47ee23aa84c89b6a78285c8\n",
            "Successfully built fvcore antlr4-python3-runtime\n",
            "\u001b[31mERROR: torchvision 0.6.1+cu101 has requirement torch==1.5.1, but you'll have torch 1.8.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement tensorboard~=2.4, but you'll have tensorboard 1.15.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: parameterized, pyyaml, yacs, portalocker, iopath, fvcore, torch, fairscale, omegaconf, antlr4-python3-runtime, hydra-core, tensorboard, faiss, vissl\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Found existing installation: torch 1.5.1+cu101\n",
            "    Uninstalling torch-1.5.1+cu101:\n",
            "      Successfully uninstalled torch-1.5.1+cu101\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "Successfully installed antlr4-python3-runtime-4.8 fairscale-0.3.6 faiss-1.5.3 fvcore-0.1.5.post20210514 hydra-core-1.0.6 iopath-0.1.8 omegaconf-2.0.6 parameterized-0.7.4 portalocker-2.3.0 pyyaml-5.4.1 tensorboard-1.15.0 torch-1.8.1 vissl-0.1.5 yacs-0.1.8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6Fxe3MWxqsI"
      },
      "source": [
        "VISSL should be successfuly installed by now and all the dependencies should be available."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Np6atgoOTPrA"
      },
      "source": [
        "import vissl\n",
        "import tensorboard\n",
        "import apex\n",
        "import torch"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFEHZ4KdxzWq"
      },
      "source": [
        "## YAML config file for Full-Finetuning\n",
        "\n",
        "VISSL provides yaml configuration files for all benchmark tasks including full finetuning on ImageNet  [here](https://github.com/facebookresearch/vissl/tree/master/configs/config/benchmark). \n",
        "\n",
        "For the purpose of this tutorial, we will use [this config file](https://github.com/facebookresearch/vissl/blob/master/configs/config/benchmark/imagenet1k_fulltune/eval_resnet_8gpu_transfer_in1k_fulltune.yaml) for full-finetuning a ResNet-50 supervised model on 1-gpu. Let's go ahead and download the [example config file](https://github.com/facebookresearch/vissl/blob/master/configs/config/benchmark/imagenet1k_fulltune/eval_resnet_8gpu_transfer_in1k_fulltune.yaml).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ufyNAeUaDSs"
      },
      "source": [
        "!mkdir -p configs/config\n",
        "!wget -q -O configs/__init__.py https://dl.fbaipublicfiles.com/vissl/tutorials/configs/__init__.py \n",
        "!wget -q -O configs/config/eval_resnet_8gpu_transfer_in1k_fulltune.yaml https://dl.fbaipublicfiles.com/vissl/tutorials/configs/eval_resnet_8gpu_transfer_in1k_fulltune.yaml"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxMXLYLpsJXj"
      },
      "source": [
        "## Download the ResNet-50 weights from Torchvision\n",
        "\n",
        "We download the weights from the [torchvision ResNet50 model](https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py#L16):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mv0quZwFsWxs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0aee00b-bfdd-4965-fde0-0dcf16a9a511"
      },
      "source": [
        "!wget https://download.pytorch.org/models/resnet50-19c8e357.pth"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-14 09:09:44--  https://download.pytorch.org/models/resnet50-19c8e357.pth\n",
            "Resolving download.pytorch.org (download.pytorch.org)... 99.86.33.48, 99.86.33.64, 99.86.33.56, ...\n",
            "Connecting to download.pytorch.org (download.pytorch.org)|99.86.33.48|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 102502400 (98M) [application/octet-stream]\n",
            "Saving to: ‘resnet50-19c8e357.pth’\n",
            "\n",
            "resnet50-19c8e357.p 100%[===================>]  97.75M   236MB/s    in 0.4s    \n",
            "\n",
            "2021-05-14 09:09:44 (236 MB/s) - ‘resnet50-19c8e357.pth’ saved [102502400/102502400]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndNMJGSRyffl"
      },
      "source": [
        "## Builtin training tool in VISSL\n",
        "\n",
        "VISSL also provides a [helper python tool](https://github.com/facebookresearch/vissl/blob/master/tools/run_distributed_engines.py) that allows to use VISSL for training purposes. This tool offers:\n",
        "- allows training and feature extraction both using VISSL. \n",
        "- also allows training on 1-gpu or multi-gpu. \n",
        "- can be used to launch multi-machine distributed training.\n",
        "\n",
        "Let's go ahead and download this tool directly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6io7qQWzCbw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6382e7ec-ccd7-40b5-994d-39939929988f"
      },
      "source": [
        "!wget https://dl.fbaipublicfiles.com/vissl/tutorials/run_distributed_engines.py"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-14 09:09:47--  https://dl.fbaipublicfiles.com/vissl/tutorials/run_distributed_engines.py\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.75.142, 104.22.74.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6568 (6.4K) [text/x-python]\n",
            "Saving to: ‘run_distributed_engines.py’\n",
            "\n",
            "\r          run_distr   0%[                    ]       0  --.-KB/s               \rrun_distributed_eng 100%[===================>]   6.41K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-05-14 09:09:47 (79.9 MB/s) - ‘run_distributed_engines.py’ saved [6568/6568]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0hng2EPY7pr"
      },
      "source": [
        "## Creating a custom data\n",
        "\n",
        "For the purpose of this tutorial, since we don't have ImageNet on the disk, we will create a dummy dataset by copying an image from COCO dataset in ImageNet dataset folder style as below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-sy6nD-RfwB"
      },
      "source": [
        "!mkdir -p dummy_data/train/class1\n",
        "!mkdir -p dummy_data/train/class2\n",
        "!mkdir -p dummy_data/val/class1\n",
        "!mkdir -p dummy_data/val/class2\n",
        "\n",
        "# create 2 classes in train and add 5 images per class\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/train/class1/img1.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/train/class1/img2.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/train/class1/img3.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/train/class1/img4.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/train/class1/img5.jpg\n",
        "\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/train/class2/img1.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/train/class2/img2.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/train/class2/img3.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/train/class2/img4.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/train/class2/img5.jpg\n",
        "\n",
        "# create 2 classes in val and add 5 images per class\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/val/class1/img1.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/val/class1/img2.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/val/class1/img3.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/val/class1/img4.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/val/class1/img5.jpg\n",
        "\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/val/class2/img1.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/val/class2/img2.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/val/class2/img3.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/val/class2/img4.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/val/class2/img5.jpg\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPGCiTsXZeW3"
      },
      "source": [
        "## Using the custom data in VISSL\n",
        "\n",
        "Next step for us is to register the dummy data we created above with VISSL. Registering the dataset involves telling VISSL about the dataset name and the paths for the dataset. For this, we create a simple json file with the metadata and save it to `configs/config/dataset_catalog.py` file.\n",
        "\n",
        "**NOTE**: VISSL uses the specific `dataset_catalog.json` under the path `configs/config/dataset_catalog.json`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8Q6LCqaWjl1"
      },
      "source": [
        "json_data = {\n",
        "    \"dummy_data_folder\": {\n",
        "      \"train\": [\n",
        "        \"/content/dummy_data/train\", \"/content/dummy_data/train\"\n",
        "      ],\n",
        "      \"val\": [\n",
        "        \"/content/dummy_data/val\", \"/content/dummy_data/val\"\n",
        "      ]\n",
        "    }\n",
        "}\n",
        "\n",
        "# use VISSL's api to save or you can use your custom code.\n",
        "from vissl.utils.io import save_file\n",
        "save_file(json_data, \"/content/configs/config/dataset_catalog.json\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otN1pB32cBHK"
      },
      "source": [
        "Next, we verify that the dataset is registered with VISSL. For that we query VISSL's dataset catalog as below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "wZBhH-s5bcHd",
        "outputId": "5465b6f3-f7cf-4f21-fd18-e1e718508ffe"
      },
      "source": [
        "from vissl.data.dataset_catalog import VisslDatasetCatalog\n",
        "\n",
        "# list all the datasets that exist in catalog\n",
        "print(VisslDatasetCatalog.list())\n",
        "\n",
        "# get the metadata of dummy_data_folder dataset\n",
        "print(VisslDatasetCatalog.get(\"dummy_data_folder\"))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-b5479c1fc208>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mvissl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_catalog\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVisslDatasetCatalog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# list all the datasets that exist in catalog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVisslDatasetCatalog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/vissl/data/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mclassy_vision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataloaderAsyncGPUWrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvissl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollators\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_collator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/classy_vision/dataset/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mclassy_vision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregistry_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimport_all_modules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mclassy_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClassyDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/classy_vision/dataset/classy_dataset.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mclassy_vision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClassyTransform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mclassy_vision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed_util\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_rank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_world_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mclassy_vision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_pos_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_class_usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/classy_vision/dataset/transforms/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transforms_video\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtransforms_video\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mclassy_vision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregistry_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimport_all_modules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mshufflenetv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msegmentation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdetection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvideo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mquantization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/models/detection/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfaster_rcnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmask_rcnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mkeypoint_rcnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/models/detection/faster_rcnn.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmisc\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmisc_nn_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultiScaleRoIAlign\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/ops/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_register_onnx_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_register_custom_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0m_register_custom_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/ops/_register_onnx_ops.py\u001b[0m in \u001b[0;36m_register_custom_op\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_register_custom_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbolic_helper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparse_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalar_type_to_onnx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalar_type_to_pytorch_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mcast_pytorch_to_onnx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbolic_opset9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mselect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munsqueeze\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msqueeze\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_cast_Long\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/onnx/symbolic_helper.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# This import monkey-patches graph manipulation methods on Graph, used for the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# ONNX symbolics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfunctools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwraps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_six\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstring_classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_unique_state_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mONNX_ARCHIVE_MODEL_PROTO_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExportTypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOperatorExportTypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainingMode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mListType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptionalType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_propagate_and_assign_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_check_onnx_proto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'TrainingMode' from 'torch.onnx' (/usr/local/lib/python3.7/dist-packages/torch/onnx/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaUMDwMdzYHN"
      },
      "source": [
        "## Run Full-Finetuning\n",
        "\n",
        "We are ready to run the full-finetuning. For the purpose of this tutorial, we will use synthetic dataset and train on dummy images. VISSL supports training on wide range of datasets and allows adding custom datasets. Please see VISSL documentation on how to use the datasets. To train on ImageNet instead: assuming your ImageNet dataset folder path is `/path/to/my/imagenet/folder/`, you can add the following command line \n",
        "input to your training command: \n",
        "```\n",
        "config.DATA.TRAIN.DATASET_NAMES=[imagenet1k_folder] \\\n",
        "config.DATA.TRAIN.DATA_SOURCES=[disk_folder] \\\n",
        "config.DATA.TRAIN.DATA_PATHS=[\"/path/to/my/imagenet/folder/train\"] \\\n",
        "config.DATA.TRAIN.LABEL_SOURCES=[disk_folder]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fM7IigSpONW0"
      },
      "source": [
        "The training command looks like:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6v0HvauIj9S2",
        "outputId": "528f8620-6eb1-48ad-a3bc-ef48a58b7641"
      },
      "source": [
        "!python3 run_distributed_engines.py \\\n",
        "    hydra.verbose=true \\\n",
        "    config=eval_resnet_8gpu_transfer_in1k_fulltune \\\n",
        "    config.DATA.TRAIN.DATA_SOURCES=[disk_folder] \\\n",
        "    config.DATA.TRAIN.LABEL_SOURCES=[disk_folder] \\\n",
        "    config.DATA.TRAIN.DATASET_NAMES=[dummy_data_folder] \\\n",
        "    config.DATA.TRAIN.BATCHSIZE_PER_REPLICA=2 \\\n",
        "    config.DATA.TEST.DATA_SOURCES=[disk_folder] \\\n",
        "    config.DATA.TEST.LABEL_SOURCES=[disk_folder] \\\n",
        "    config.DATA.TEST.DATASET_NAMES=[dummy_data_folder] \\\n",
        "    config.DATA.TEST.BATCHSIZE_PER_REPLICA=2 \\\n",
        "    config.OPTIMIZER.num_epochs=2 \\\n",
        "    config.OPTIMIZER.param_schedulers.lr.values=[0.01,0.001] \\\n",
        "    config.OPTIMIZER.param_schedulers.lr.milestones=[1] \\\n",
        "    config.DISTRIBUTED.NUM_NODES=1 \\\n",
        "    config.DISTRIBUTED.NUM_PROC_PER_NODE=1 \\\n",
        "    config.CHECKPOINT.DIR=\"./checkpoints\" \\\n",
        "    config.MODEL.WEIGHTS_INIT.PARAMS_FILE=\"/content/resnet50-19c8e357.pth\" \\\n",
        "    config.MODEL.WEIGHTS_INIT.APPEND_PREFIX=\"trunk._feature_blocks.\" \\\n",
        "    config.MODEL.WEIGHTS_INIT.STATE_DICT_KEY_NAME=\"\"\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "####### overrides: ['hydra.verbose=true', 'config=eval_resnet_8gpu_transfer_in1k_fulltune', 'config.DATA.TRAIN.DATA_SOURCES=[disk_folder]', 'config.DATA.TRAIN.LABEL_SOURCES=[disk_folder]', 'config.DATA.TRAIN.DATASET_NAMES=[dummy_data_folder]', 'config.DATA.TRAIN.BATCHSIZE_PER_REPLICA=2', 'config.DATA.TEST.DATA_SOURCES=[disk_folder]', 'config.DATA.TEST.LABEL_SOURCES=[disk_folder]', 'config.DATA.TEST.DATASET_NAMES=[dummy_data_folder]', 'config.DATA.TEST.BATCHSIZE_PER_REPLICA=2', 'config.OPTIMIZER.num_epochs=2', 'config.OPTIMIZER.param_schedulers.lr.values=[0.01,0.001]', 'config.OPTIMIZER.param_schedulers.lr.milestones=[1]', 'config.DISTRIBUTED.NUM_NODES=1', 'config.DISTRIBUTED.NUM_PROC_PER_NODE=1', 'config.CHECKPOINT.DIR=./checkpoints', 'config.MODEL.WEIGHTS_INIT.PARAMS_FILE=/content/resnet50-19c8e357.pth', 'config.MODEL.WEIGHTS_INIT.APPEND_PREFIX=trunk._feature_blocks.', 'config.MODEL.WEIGHTS_INIT.STATE_DICT_KEY_NAME=', 'hydra.verbose=true']\n",
            "INFO 2021-01-25 20:27:16,914 __init__.py:  32: Provided Config has latest version: 1\n",
            "[PathManager] Attempting to register prefix 'http://' from the following call stack:\n",
            "  File \"run_distributed_engines.py\", line 194, in <module>\n",
            "    hydra_main(overrides=overrides)\n",
            "  File \"run_distributed_engines.py\", line 179, in hydra_main\n",
            "    hook_generator=default_hook_generator,\n",
            "  File \"run_distributed_engines.py\", line 77, in launch_distributed\n",
            "    set_env_vars(local_rank=0, node_id=node_id, cfg=cfg)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/vissl/utils/env.py\", line 31, in set_env_vars\n",
            "    PathManager.register_handler(HTTPURLHandler(), allow_override=True)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fvcore/common/file_io.py\", line 287, in register_handler\n",
            "    + \"\".join(traceback.format_stack(limit=5))\n",
            "\n",
            "[PathManager] Prefix 'http://' is already registered by <class 'iopath.common.file_io.HTTPURLHandler'>. We will override the old handler. To avoid such conflicts, create a project-specific PathManager instead.\n",
            "[PathManager] Attempting to register prefix 'https://' from the following call stack:\n",
            "  File \"run_distributed_engines.py\", line 194, in <module>\n",
            "    hydra_main(overrides=overrides)\n",
            "  File \"run_distributed_engines.py\", line 179, in hydra_main\n",
            "    hook_generator=default_hook_generator,\n",
            "  File \"run_distributed_engines.py\", line 77, in launch_distributed\n",
            "    set_env_vars(local_rank=0, node_id=node_id, cfg=cfg)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/vissl/utils/env.py\", line 31, in set_env_vars\n",
            "    PathManager.register_handler(HTTPURLHandler(), allow_override=True)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fvcore/common/file_io.py\", line 287, in register_handler\n",
            "    + \"\".join(traceback.format_stack(limit=5))\n",
            "\n",
            "[PathManager] Prefix 'https://' is already registered by <class 'iopath.common.file_io.HTTPURLHandler'>. We will override the old handler. To avoid such conflicts, create a project-specific PathManager instead.\n",
            "[PathManager] Attempting to register prefix 'ftp://' from the following call stack:\n",
            "  File \"run_distributed_engines.py\", line 194, in <module>\n",
            "    hydra_main(overrides=overrides)\n",
            "  File \"run_distributed_engines.py\", line 179, in hydra_main\n",
            "    hook_generator=default_hook_generator,\n",
            "  File \"run_distributed_engines.py\", line 77, in launch_distributed\n",
            "    set_env_vars(local_rank=0, node_id=node_id, cfg=cfg)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/vissl/utils/env.py\", line 31, in set_env_vars\n",
            "    PathManager.register_handler(HTTPURLHandler(), allow_override=True)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fvcore/common/file_io.py\", line 287, in register_handler\n",
            "    + \"\".join(traceback.format_stack(limit=5))\n",
            "\n",
            "[PathManager] Prefix 'ftp://' is already registered by <class 'iopath.common.file_io.HTTPURLHandler'>. We will override the old handler. To avoid such conflicts, create a project-specific PathManager instead.\n",
            "INFO 2021-01-25 20:27:16,916 run_distributed_engines.py: 163: Spawning process for node_id: 0, local_rank: 0, dist_rank: 0, dist_run_id: localhost:55537\n",
            "[PathManager] Attempting to register prefix 'http://' from the following call stack:\n",
            "  File \"run_distributed_engines.py\", line 166, in _distributed_worker\n",
            "    process_main(cfg, dist_run_id, local_rank=local_rank, node_id=node_id)\n",
            "  File \"run_distributed_engines.py\", line 159, in process_main\n",
            "    hook_generator=hook_generator,\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/vissl/engines/train.py\", line 60, in train_main\n",
            "    set_env_vars(local_rank, node_id, cfg)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/vissl/utils/env.py\", line 31, in set_env_vars\n",
            "    PathManager.register_handler(HTTPURLHandler(), allow_override=True)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fvcore/common/file_io.py\", line 287, in register_handler\n",
            "    + \"\".join(traceback.format_stack(limit=5))\n",
            "\n",
            "[PathManager] Prefix 'http://' is already registered by <class 'iopath.common.file_io.HTTPURLHandler'>. We will override the old handler. To avoid such conflicts, create a project-specific PathManager instead.\n",
            "[PathManager] Attempting to register prefix 'https://' from the following call stack:\n",
            "  File \"run_distributed_engines.py\", line 166, in _distributed_worker\n",
            "    process_main(cfg, dist_run_id, local_rank=local_rank, node_id=node_id)\n",
            "  File \"run_distributed_engines.py\", line 159, in process_main\n",
            "    hook_generator=hook_generator,\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/vissl/engines/train.py\", line 60, in train_main\n",
            "    set_env_vars(local_rank, node_id, cfg)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/vissl/utils/env.py\", line 31, in set_env_vars\n",
            "    PathManager.register_handler(HTTPURLHandler(), allow_override=True)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fvcore/common/file_io.py\", line 287, in register_handler\n",
            "    + \"\".join(traceback.format_stack(limit=5))\n",
            "\n",
            "[PathManager] Prefix 'https://' is already registered by <class 'iopath.common.file_io.HTTPURLHandler'>. We will override the old handler. To avoid such conflicts, create a project-specific PathManager instead.\n",
            "[PathManager] Attempting to register prefix 'ftp://' from the following call stack:\n",
            "  File \"run_distributed_engines.py\", line 166, in _distributed_worker\n",
            "    process_main(cfg, dist_run_id, local_rank=local_rank, node_id=node_id)\n",
            "  File \"run_distributed_engines.py\", line 159, in process_main\n",
            "    hook_generator=hook_generator,\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/vissl/engines/train.py\", line 60, in train_main\n",
            "    set_env_vars(local_rank, node_id, cfg)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/vissl/utils/env.py\", line 31, in set_env_vars\n",
            "    PathManager.register_handler(HTTPURLHandler(), allow_override=True)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fvcore/common/file_io.py\", line 287, in register_handler\n",
            "    + \"\".join(traceback.format_stack(limit=5))\n",
            "\n",
            "[PathManager] Prefix 'ftp://' is already registered by <class 'iopath.common.file_io.HTTPURLHandler'>. We will override the old handler. To avoid such conflicts, create a project-specific PathManager instead.\n",
            "INFO 2021-01-25 20:27:16,917 train.py:  66: Env set for rank: 0, dist_rank: 0\n",
            "INFO 2021-01-25 20:27:16,917 env.py:  41: CLICOLOR:\t1\n",
            "INFO 2021-01-25 20:27:16,917 env.py:  41: CLOUDSDK_CONFIG:\t/content/.config\n",
            "INFO 2021-01-25 20:27:16,917 env.py:  41: CLOUDSDK_PYTHON:\tpython3\n",
            "INFO 2021-01-25 20:27:16,917 env.py:  41: COLAB_GPU:\t1\n",
            "INFO 2021-01-25 20:27:16,917 env.py:  41: CUDA_PKG_VERSION:\t10-1=10.1.243-1\n",
            "INFO 2021-01-25 20:27:16,917 env.py:  41: CUDA_VERSION:\t10.1.243\n",
            "INFO 2021-01-25 20:27:16,917 env.py:  41: CUDNN_VERSION:\t7.6.5.32\n",
            "INFO 2021-01-25 20:27:16,917 env.py:  41: DATALAB_SETTINGS_OVERRIDES:\t{\"kernelManagerProxyPort\":6000,\"kernelManagerProxyHost\":\"172.28.0.3\",\"jupyterArgs\":[\"--ip=\\\"172.28.0.2\\\"\"],\"debugAdapterMultiplexerPath\":\"/usr/local/bin/dap_multiplexer\"}\n",
            "INFO 2021-01-25 20:27:16,917 env.py:  41: DEBIAN_FRONTEND:\tnoninteractive\n",
            "INFO 2021-01-25 20:27:16,917 env.py:  41: ENV:\t/root/.bashrc\n",
            "INFO 2021-01-25 20:27:16,917 env.py:  41: GCE_METADATA_TIMEOUT:\t0\n",
            "INFO 2021-01-25 20:27:16,917 env.py:  41: GCS_READ_CACHE_BLOCK_SIZE_MB:\t16\n",
            "INFO 2021-01-25 20:27:16,918 env.py:  41: GIT_PAGER:\tcat\n",
            "INFO 2021-01-25 20:27:16,918 env.py:  41: GLIBCPP_FORCE_NEW:\t1\n",
            "INFO 2021-01-25 20:27:16,918 env.py:  41: GLIBCXX_FORCE_NEW:\t1\n",
            "INFO 2021-01-25 20:27:16,918 env.py:  41: HOME:\t/root\n",
            "INFO 2021-01-25 20:27:16,918 env.py:  41: HOSTNAME:\t263513be104f\n",
            "INFO 2021-01-25 20:27:16,918 env.py:  41: JPY_PARENT_PID:\t50\n",
            "INFO 2021-01-25 20:27:16,918 env.py:  41: LANG:\ten_US.UTF-8\n",
            "INFO 2021-01-25 20:27:16,918 env.py:  41: LAST_FORCED_REBUILD:\t20210119\n",
            "INFO 2021-01-25 20:27:16,918 env.py:  41: LD_LIBRARY_PATH:\t/usr/lib64-nvidia\n",
            "INFO 2021-01-25 20:27:16,918 env.py:  41: LD_PRELOAD:\t/usr/lib/x86_64-linux-gnu/libtcmalloc.so.4\n",
            "INFO 2021-01-25 20:27:16,918 env.py:  41: LIBRARY_PATH:\t/usr/local/cuda/lib64/stubs\n",
            "INFO 2021-01-25 20:27:16,918 env.py:  41: LOCAL_RANK:\t0\n",
            "INFO 2021-01-25 20:27:16,918 env.py:  41: MPLBACKEND:\tmodule://ipykernel.pylab.backend_inline\n",
            "INFO 2021-01-25 20:27:16,918 env.py:  41: NCCL_VERSION:\t2.8.3\n",
            "INFO 2021-01-25 20:27:16,918 env.py:  41: NO_GCE_CHECK:\tTrue\n",
            "INFO 2021-01-25 20:27:16,919 env.py:  41: NVIDIA_DRIVER_CAPABILITIES:\tcompute,utility\n",
            "INFO 2021-01-25 20:27:16,919 env.py:  41: NVIDIA_REQUIRE_CUDA:\tcuda>=10.1 brand=tesla,driver>=396,driver<397 brand=tesla,driver>=410,driver<411 brand=tesla,driver>=418,driver<419\n",
            "INFO 2021-01-25 20:27:16,919 env.py:  41: NVIDIA_VISIBLE_DEVICES:\tall\n",
            "INFO 2021-01-25 20:27:16,919 env.py:  41: OLDPWD:\t/\n",
            "INFO 2021-01-25 20:27:16,919 env.py:  41: PAGER:\tcat\n",
            "INFO 2021-01-25 20:27:16,919 env.py:  41: PATH:\t/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/opt/bin\n",
            "INFO 2021-01-25 20:27:16,919 env.py:  41: PWD:\t/content\n",
            "INFO 2021-01-25 20:27:16,919 env.py:  41: PYTHONPATH:\t/env/python\n",
            "INFO 2021-01-25 20:27:16,919 env.py:  41: PYTHONWARNINGS:\tignore:::pip._internal.cli.base_command\n",
            "INFO 2021-01-25 20:27:16,919 env.py:  41: RANK:\t0\n",
            "INFO 2021-01-25 20:27:16,919 env.py:  41: SHELL:\t/bin/bash\n",
            "INFO 2021-01-25 20:27:16,919 env.py:  41: SHLVL:\t1\n",
            "INFO 2021-01-25 20:27:16,919 env.py:  41: TBE_CREDS_ADDR:\t172.28.0.1:8008\n",
            "INFO 2021-01-25 20:27:16,919 env.py:  41: TERM:\txterm-color\n",
            "INFO 2021-01-25 20:27:16,919 env.py:  41: TF_FORCE_GPU_ALLOW_GROWTH:\ttrue\n",
            "INFO 2021-01-25 20:27:16,920 env.py:  41: WORLD_SIZE:\t1\n",
            "INFO 2021-01-25 20:27:16,920 env.py:  41: _:\t/usr/bin/python3\n",
            "INFO 2021-01-25 20:27:16,920 env.py:  41: __EGL_VENDOR_LIBRARY_DIRS:\t/usr/lib64-nvidia:/usr/share/glvnd/egl_vendor.d/\n",
            "INFO 2021-01-25 20:27:16,920 misc.py:  86: Set start method of multiprocessing to forkserver\n",
            "INFO 2021-01-25 20:27:16,920 train.py:  77: Setting seed....\n",
            "INFO 2021-01-25 20:27:16,920 misc.py:  99: MACHINE SEED: 1\n",
            "INFO 2021-01-25 20:27:16,957 hydra_config.py: 140: Training with config:\n",
            "INFO 2021-01-25 20:27:16,962 hydra_config.py: 144: {'CHECKPOINT': {'APPEND_DISTR_RUN_ID': False,\n",
            "                'AUTO_RESUME': True,\n",
            "                'BACKEND': 'disk',\n",
            "                'CHECKPOINT_FREQUENCY': 1,\n",
            "                'CHECKPOINT_ITER_FREQUENCY': -1,\n",
            "                'DIR': './checkpoints',\n",
            "                'LATEST_CHECKPOINT_RESUME_FILE_NUM': 1,\n",
            "                'OVERWRITE_EXISTING': False,\n",
            "                'USE_SYMLINK_CHECKPOINT_FOR_RESUME': False},\n",
            " 'CLUSTERFIT': {'CLUSTER_BACKEND': 'faiss',\n",
            "                'FEATURES': {'DATASET_NAME': '',\n",
            "                             'DATA_PARTITION': 'TRAIN',\n",
            "                             'LAYER_NAME': ''},\n",
            "                'NUM_CLUSTERS': 16000,\n",
            "                'N_ITER': 50},\n",
            " 'DATA': {'DDP_BUCKET_CAP_MB': 25,\n",
            "          'ENABLE_ASYNC_GPU_COPY': True,\n",
            "          'NUM_DATALOADER_WORKERS': 5,\n",
            "          'PIN_MEMORY': True,\n",
            "          'TEST': {'BATCHSIZE_PER_REPLICA': 2,\n",
            "                   'COLLATE_FUNCTION': 'default_collate',\n",
            "                   'COLLATE_FUNCTION_PARAMS': {},\n",
            "                   'COPY_DESTINATION_DIR': '/tmp/imagenet1k/',\n",
            "                   'COPY_TO_LOCAL_DISK': False,\n",
            "                   'DATASET_NAMES': ['dummy_data_folder'],\n",
            "                   'DATA_LIMIT': -1,\n",
            "                   'DATA_PATHS': [],\n",
            "                   'DATA_SOURCES': ['disk_folder'],\n",
            "                   'DEFAULT_GRAY_IMG_SIZE': 224,\n",
            "                   'DROP_LAST': False,\n",
            "                   'ENABLE_QUEUE_DATASET': False,\n",
            "                   'INPUT_KEY_NAMES': ['data'],\n",
            "                   'LABEL_PATHS': [],\n",
            "                   'LABEL_SOURCES': ['disk_folder'],\n",
            "                   'LABEL_TYPE': 'standard',\n",
            "                   'MMAP_MODE': True,\n",
            "                   'TARGET_KEY_NAMES': ['label'],\n",
            "                   'TRANSFORMS': [{'name': 'Resize', 'size': 256},\n",
            "                                  {'name': 'CenterCrop', 'size': 224},\n",
            "                                  {'name': 'ToTensor'},\n",
            "                                  {'mean': [0.485, 0.456, 0.406],\n",
            "                                   'name': 'Normalize',\n",
            "                                   'std': [0.229, 0.224, 0.225]}],\n",
            "                   'USE_STATEFUL_DISTRIBUTED_SAMPLER': False},\n",
            "          'TRAIN': {'BATCHSIZE_PER_REPLICA': 2,\n",
            "                    'COLLATE_FUNCTION': 'default_collate',\n",
            "                    'COLLATE_FUNCTION_PARAMS': {},\n",
            "                    'COPY_DESTINATION_DIR': '/tmp/imagenet1k/',\n",
            "                    'COPY_TO_LOCAL_DISK': False,\n",
            "                    'DATASET_NAMES': ['dummy_data_folder'],\n",
            "                    'DATA_LIMIT': -1,\n",
            "                    'DATA_PATHS': [],\n",
            "                    'DATA_SOURCES': ['disk_folder'],\n",
            "                    'DEFAULT_GRAY_IMG_SIZE': 224,\n",
            "                    'DROP_LAST': False,\n",
            "                    'ENABLE_QUEUE_DATASET': False,\n",
            "                    'INPUT_KEY_NAMES': ['data'],\n",
            "                    'LABEL_PATHS': [],\n",
            "                    'LABEL_SOURCES': ['disk_folder'],\n",
            "                    'LABEL_TYPE': 'standard',\n",
            "                    'MMAP_MODE': True,\n",
            "                    'TARGET_KEY_NAMES': ['label'],\n",
            "                    'TRANSFORMS': [{'name': 'RandomResizedCrop', 'size': 224},\n",
            "                                   {'name': 'RandomHorizontalFlip'},\n",
            "                                   {'name': 'ToTensor'},\n",
            "                                   {'mean': [0.485, 0.456, 0.406],\n",
            "                                    'name': 'Normalize',\n",
            "                                    'std': [0.229, 0.224, 0.225]}],\n",
            "                    'USE_STATEFUL_DISTRIBUTED_SAMPLER': False}},\n",
            " 'DISTRIBUTED': {'BACKEND': 'nccl',\n",
            "                 'BROADCAST_BUFFERS': True,\n",
            "                 'INIT_METHOD': 'tcp',\n",
            "                 'MANUAL_GRADIENT_REDUCTION': False,\n",
            "                 'NCCL_DEBUG': False,\n",
            "                 'NCCL_SOCKET_NTHREADS': '',\n",
            "                 'NUM_NODES': 1,\n",
            "                 'NUM_PROC_PER_NODE': 1,\n",
            "                 'RUN_ID': 'auto'},\n",
            " 'IMG_RETRIEVAL': {'DATASET_PATH': '',\n",
            "                   'EVAL_BINARY_PATH': '',\n",
            "                   'EVAL_DATASET_NAME': 'Paris',\n",
            "                   'FEATS_PROCESSING_TYPE': '',\n",
            "                   'GEM_POOL_POWER': 4.0,\n",
            "                   'N_PCA': 512,\n",
            "                   'RESIZE_IMG': 1024,\n",
            "                   'SHOULD_TRAIN_PCA_OR_WHITENING': True,\n",
            "                   'SPATIAL_LEVELS': 3,\n",
            "                   'TEMP_DIR': '/tmp/instance_retrieval/',\n",
            "                   'TRAIN_DATASET_NAME': 'Oxford',\n",
            "                   'WHITEN_IMG_LIST': ''},\n",
            " 'LOG_FREQUENCY': 100,\n",
            " 'LOSS': {'CrossEntropyLoss': {'ignore_index': -1},\n",
            "          'bce_logits_multiple_output_single_target': {'normalize_output': False,\n",
            "                                                       'reduction': 'none',\n",
            "                                                       'world_size': 1},\n",
            "          'cross_entropy_multiple_output_single_target': {'ignore_index': -1,\n",
            "                                                          'normalize_output': False,\n",
            "                                                          'reduction': 'mean',\n",
            "                                                          'temperature': 1.0,\n",
            "                                                          'weight': None},\n",
            "          'deepclusterv2_loss': {'BATCHSIZE_PER_REPLICA': 256,\n",
            "                                 'DROP_LAST': True,\n",
            "                                 'kmeans_iters': 10,\n",
            "                                 'memory_params': {'crops_for_mb': [0],\n",
            "                                                   'embedding_dim': 128},\n",
            "                                 'num_clusters': [3000, 3000, 3000],\n",
            "                                 'num_crops': 2,\n",
            "                                 'num_train_samples': -1,\n",
            "                                 'temperature': 0.1},\n",
            "          'moco_loss': {'embedding_dim': 128,\n",
            "                        'momentum': 0.999,\n",
            "                        'queue_size': 65536,\n",
            "                        'temperature': 0.2},\n",
            "          'multicrop_simclr_info_nce_loss': {'buffer_params': {'effective_batch_size': 4096,\n",
            "                                                               'embedding_dim': 128,\n",
            "                                                               'world_size': 64},\n",
            "                                             'num_crops': 2,\n",
            "                                             'temperature': 0.1},\n",
            "          'name': 'cross_entropy_multiple_output_single_target',\n",
            "          'nce_loss_with_memory': {'loss_type': 'nce',\n",
            "                                   'loss_weights': [1.0],\n",
            "                                   'memory_params': {'embedding_dim': 128,\n",
            "                                                     'memory_size': -1,\n",
            "                                                     'momentum': 0.5,\n",
            "                                                     'norm_init': True,\n",
            "                                                     'update_mem_on_forward': True},\n",
            "                                   'negative_sampling_params': {'num_negatives': 16000,\n",
            "                                                                'type': 'random'},\n",
            "                                   'norm_constant': -1,\n",
            "                                   'norm_embedding': True,\n",
            "                                   'num_train_samples': -1,\n",
            "                                   'temperature': 0.07,\n",
            "                                   'update_mem_with_emb_index': -100},\n",
            "          'simclr_info_nce_loss': {'buffer_params': {'effective_batch_size': 4096,\n",
            "                                                     'embedding_dim': 128,\n",
            "                                                     'world_size': 64},\n",
            "                                   'temperature': 0.1},\n",
            "          'swav_loss': {'crops_for_assign': [0, 1],\n",
            "                        'embedding_dim': 128,\n",
            "                        'epsilon': 0.05,\n",
            "                        'normalize_last_layer': True,\n",
            "                        'num_crops': 2,\n",
            "                        'num_iters': 3,\n",
            "                        'num_prototypes': [3000],\n",
            "                        'output_dir': '',\n",
            "                        'queue': {'local_queue_length': 0,\n",
            "                                  'queue_length': 0,\n",
            "                                  'start_iter': 0},\n",
            "                        'temp_hard_assignment_iters': 0,\n",
            "                        'temperature': 0.1,\n",
            "                        'use_double_precision': False},\n",
            "          'swav_momentum_loss': {'crops_for_assign': [0, 1],\n",
            "                                 'embedding_dim': 128,\n",
            "                                 'epsilon': 0.05,\n",
            "                                 'momentum': 0.99,\n",
            "                                 'momentum_eval_mode_iter_start': 0,\n",
            "                                 'normalize_last_layer': True,\n",
            "                                 'num_crops': 2,\n",
            "                                 'num_iters': 3,\n",
            "                                 'num_prototypes': [3000],\n",
            "                                 'queue': {'local_queue_length': 0,\n",
            "                                           'queue_length': 0,\n",
            "                                           'start_iter': 0},\n",
            "                                 'temperature': 0.1,\n",
            "                                 'use_double_precision': False}},\n",
            " 'MACHINE': {'DEVICE': 'gpu'},\n",
            " 'METERS': {'accuracy_list_meter': {'meter_names': [],\n",
            "                                    'num_meters': 1,\n",
            "                                    'topk_values': [1, 5]},\n",
            "            'enable_training_meter': True,\n",
            "            'mean_ap_list_meter': {'max_cpu_capacity': -1,\n",
            "                                   'meter_names': [],\n",
            "                                   'num_classes': 9605,\n",
            "                                   'num_meters': 1},\n",
            "            'name': 'accuracy_list_meter'},\n",
            " 'MODEL': {'ACTIVATION_CHECKPOINTING': {'NUM_ACTIVATION_CHECKPOINTING_SPLITS': 2,\n",
            "                                        'USE_ACTIVATION_CHECKPOINTING': False},\n",
            "           'AMP_PARAMS': {'AMP_ARGS': {'opt_level': 'O1'},\n",
            "                          'AMP_TYPE': 'apex',\n",
            "                          'USE_AMP': False},\n",
            "           'CUDA_CACHE': {'CLEAR_CUDA_CACHE': False, 'CLEAR_FREQ': 100},\n",
            "           'FEATURE_EVAL_SETTINGS': {'EVAL_MODE_ON': False,\n",
            "                                     'EVAL_TRUNK_AND_HEAD': False,\n",
            "                                     'EXTRACT_TRUNK_FEATURES_ONLY': False,\n",
            "                                     'FREEZE_TRUNK_AND_HEAD': False,\n",
            "                                     'FREEZE_TRUNK_ONLY': False,\n",
            "                                     'LINEAR_EVAL_FEAT_POOL_OPS_MAP': [],\n",
            "                                     'SHOULD_FLATTEN_FEATS': True},\n",
            "           'HEAD': {'BATCHNORM_EPS': 1e-05,\n",
            "                    'BATCHNORM_MOMENTUM': 0.1,\n",
            "                    'PARAMS': [['mlp', {'dims': [2048, 1000]}]],\n",
            "                    'PARAMS_MULTIPLIER': 1.0},\n",
            "           'INPUT_TYPE': 'rgb',\n",
            "           'MODEL_COMPLEXITY': {'COMPUTE_COMPLEXITY': False,\n",
            "                                'INPUT_SHAPE': [3, 224, 224]},\n",
            "           'MULTI_INPUT_HEAD_MAPPING': [],\n",
            "           'NON_TRAINABLE_PARAMS': [],\n",
            "           'SINGLE_PASS_EVERY_CROP': False,\n",
            "           'SYNC_BN_CONFIG': {'CONVERT_BN_TO_SYNC_BN': False,\n",
            "                              'GROUP_SIZE': -1,\n",
            "                              'SYNC_BN_TYPE': 'pytorch'},\n",
            "           'TEMP_FROZEN_PARAMS_ITER_MAP': [],\n",
            "           'TRUNK': {'NAME': 'resnet',\n",
            "                     'TRUNK_PARAMS': {'EFFICIENT_NETS': {},\n",
            "                                      'REGNET': {},\n",
            "                                      'RESNETS': {'DEPTH': 50,\n",
            "                                                  'GROUPS': 1,\n",
            "                                                  'LAYER4_STRIDE': 2,\n",
            "                                                  'NORM': 'BatchNorm',\n",
            "                                                  'WIDTH_MULTIPLIER': 1,\n",
            "                                                  'WIDTH_PER_GROUP': 64,\n",
            "                                                  'ZERO_INIT_RESIDUAL': False}}},\n",
            "           'WEIGHTS_INIT': {'APPEND_PREFIX': 'trunk._feature_blocks.',\n",
            "                            'PARAMS_FILE': '/content/resnet50-19c8e357.pth',\n",
            "                            'REMOVE_PREFIX': '',\n",
            "                            'SKIP_LAYERS': ['num_batches_tracked'],\n",
            "                            'STATE_DICT_KEY_NAME': ''}},\n",
            " 'MONITOR_PERF_STATS': True,\n",
            " 'MULTI_PROCESSING_METHOD': 'forkserver',\n",
            " 'NEAREST_NEIGHBOR': {'L2_NORM_FEATS': False, 'SIGMA': 0.1, 'TOPK': 200},\n",
            " 'OPTIMIZER': {'head_optimizer_params': {'use_different_lr': False,\n",
            "                                         'use_different_wd': False,\n",
            "                                         'weight_decay': 0.0},\n",
            "               'larc_config': {'clip': False,\n",
            "                               'eps': 1e-08,\n",
            "                               'trust_coefficient': 0.001},\n",
            "               'momentum': 0.9,\n",
            "               'name': 'sgd',\n",
            "               'nesterov': True,\n",
            "               'num_epochs': 2,\n",
            "               'param_schedulers': {'lr': {'auto_lr_scaling': {'auto_scale': True,\n",
            "                                                               'base_lr_batch_size': 256,\n",
            "                                                               'base_value': 0.1},\n",
            "                                           'end_value': 0.0,\n",
            "                                           'interval_scaling': [],\n",
            "                                           'lengths': [],\n",
            "                                           'milestones': [1],\n",
            "                                           'name': 'multistep',\n",
            "                                           'schedulers': [],\n",
            "                                           'start_value': 0.1,\n",
            "                                           'update_interval': 'epoch',\n",
            "                                           'value': 0.1,\n",
            "                                           'values': [0.00078125, 7.813e-05]},\n",
            "                                    'lr_head': {'auto_lr_scaling': {'auto_scale': True,\n",
            "                                                                    'base_lr_batch_size': 256,\n",
            "                                                                    'base_value': 0.1},\n",
            "                                                'end_value': 0.0,\n",
            "                                                'interval_scaling': [],\n",
            "                                                'lengths': [],\n",
            "                                                'milestones': [1],\n",
            "                                                'name': 'multistep',\n",
            "                                                'schedulers': [],\n",
            "                                                'start_value': 0.1,\n",
            "                                                'update_interval': 'epoch',\n",
            "                                                'value': 0.1,\n",
            "                                                'values': [0.00078125,\n",
            "                                                           7.813e-05]}},\n",
            "               'regularize_bias': True,\n",
            "               'regularize_bn': False,\n",
            "               'use_larc': False,\n",
            "               'weight_decay': 0.0},\n",
            " 'PERF_STAT_FREQUENCY': -1,\n",
            " 'ROLLING_BTIME_FREQ': -1,\n",
            " 'SEED_VALUE': 1,\n",
            " 'SVM': {'cls_list': [],\n",
            "         'costs': {'base': -1.0,\n",
            "                   'costs_list': [0.1, 0.01],\n",
            "                   'power_range': [4, 20]},\n",
            "         'cross_val_folds': 3,\n",
            "         'dual': True,\n",
            "         'force_retrain': False,\n",
            "         'loss': 'squared_hinge',\n",
            "         'low_shot': {'dataset_name': 'voc',\n",
            "                      'k_values': [1, 2, 4, 8, 16, 32, 64, 96],\n",
            "                      'sample_inds': [1, 2, 3, 4, 5]},\n",
            "         'max_iter': 2000,\n",
            "         'normalize': True,\n",
            "         'penalty': 'l2'},\n",
            " 'TENSORBOARD_SETUP': {'EXPERIMENT_LOG_DIR': 'tensorboard',\n",
            "                       'FLUSH_EVERY_N_MIN': 5,\n",
            "                       'LOG_DIR': '.',\n",
            "                       'LOG_PARAMS': True,\n",
            "                       'LOG_PARAMS_EVERY_N_ITERS': 310,\n",
            "                       'LOG_PARAMS_GRADIENTS': True,\n",
            "                       'USE_TENSORBOARD': False},\n",
            " 'TEST_EVERY_NUM_EPOCH': 1,\n",
            " 'TEST_MODEL': True,\n",
            " 'TEST_ONLY': False,\n",
            " 'TRAINER': {'TASK_NAME': 'self_supervision_task',\n",
            "             'TRAIN_STEP_NAME': 'standard_train_step'},\n",
            " 'VERBOSE': True}\n",
            "INFO 2021-01-25 20:27:17,291 train.py:  89: System config:\n",
            "-------------------  ---------------------------------------------------------------\n",
            "sys.platform         linux\n",
            "Python               3.6.9 (default, Oct  8 2020, 12:12:24) [GCC 8.4.0]\n",
            "numpy                1.19.5\n",
            "Pillow               7.0.0\n",
            "vissl                0.1.5 @/usr/local/lib/python3.6/dist-packages/vissl\n",
            "GPU available        True\n",
            "GPU 0                Tesla T4\n",
            "CUDA_HOME            /usr/local/cuda\n",
            "torchvision          0.6.1+cu101 @/usr/local/lib/python3.6/dist-packages/torchvision\n",
            "hydra                1.0.5 @/usr/local/lib/python3.6/dist-packages/hydra\n",
            "classy_vision        0.6.0.dev @/usr/local/lib/python3.6/dist-packages/classy_vision\n",
            "tensorboard          1.15.0\n",
            "apex                 0.1 @/usr/local/lib/python3.6/dist-packages/apex\n",
            "cv2                  4.1.2\n",
            "PyTorch              1.5.1+cu101 @/usr/local/lib/python3.6/dist-packages/torch\n",
            "PyTorch debug build  False\n",
            "-------------------  ---------------------------------------------------------------\n",
            "PyTorch built with:\n",
            "  - GCC 7.3\n",
            "  - C++ Version: 201402\n",
            "  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 10.1\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\n",
            "  - CuDNN 7.6.3\n",
            "  - Magma 2.5.2\n",
            "  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, \n",
            "\n",
            "CPU info:\n",
            "-------------------  ------------------------------\n",
            "Architecture         x86_64\n",
            "CPU op-mode(s)       32-bit, 64-bit\n",
            "Byte Order           Little Endian\n",
            "CPU(s)               2\n",
            "On-line CPU(s) list  0,1\n",
            "Thread(s) per core   2\n",
            "Core(s) per socket   1\n",
            "Socket(s)            1\n",
            "NUMA node(s)         1\n",
            "Vendor ID            GenuineIntel\n",
            "CPU family           6\n",
            "Model                79\n",
            "Model name           Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "Stepping             0\n",
            "CPU MHz              2199.998\n",
            "BogoMIPS             4399.99\n",
            "Hypervisor vendor    KVM\n",
            "Virtualization type  full\n",
            "L1d cache            32K\n",
            "L1i cache            32K\n",
            "L2 cache             256K\n",
            "L3 cache             56320K\n",
            "NUMA node0 CPU(s)    0,1\n",
            "-------------------  ------------------------------\n",
            "INFO 2021-01-25 20:27:17,291 train_task.py: 192: Not using Automatic Mixed Precision\n",
            "INFO 2021-01-25 20:27:17,292 trainer_main.py: 109: Using Distributed init method: tcp://localhost:55537, world_size: 1, rank: 0\n",
            "INFO 2021-01-25 20:27:17,293 trainer_main.py: 130: | initialized host 263513be104f as rank 0 (0)\n",
            "INFO 2021-01-25 20:27:17,294 ssl_dataset.py: 130: Rank: 0 split: TEST Data files:\n",
            "['/content/dummy_data/val']\n",
            "INFO 2021-01-25 20:27:17,294 ssl_dataset.py: 133: Rank: 0 split: TEST Label files:\n",
            "['/content/dummy_data/val']\n",
            "INFO 2021-01-25 20:27:17,294 disk_dataset.py:  81: Loaded 10 samples from folder /content/dummy_data/val\n",
            "INFO 2021-01-25 20:27:17,295 ssl_dataset.py: 130: Rank: 0 split: TRAIN Data files:\n",
            "['/content/dummy_data/train']\n",
            "INFO 2021-01-25 20:27:17,295 ssl_dataset.py: 133: Rank: 0 split: TRAIN Label files:\n",
            "['/content/dummy_data/train']\n",
            "INFO 2021-01-25 20:27:17,295 disk_dataset.py:  81: Loaded 10 samples from folder /content/dummy_data/train\n",
            "INFO 2021-01-25 20:27:17,295 misc.py:  86: Set start method of multiprocessing to forkserver\n",
            "INFO 2021-01-25 20:27:17,295 __init__.py:  91: Created the Distributed Sampler....\n",
            "INFO 2021-01-25 20:27:17,295 __init__.py:  72: Distributed Sampler config:\n",
            "{'num_replicas': 1, 'rank': 0, 'epoch': 0, 'num_samples': 10, 'total_size': 10, 'shuffle': True}\n",
            "INFO 2021-01-25 20:27:17,295 __init__.py: 155: Wrapping the dataloader to async device copies\n",
            "INFO 2021-01-25 20:27:27,291 misc.py:  86: Set start method of multiprocessing to forkserver\n",
            "INFO 2021-01-25 20:27:27,291 __init__.py:  91: Created the Distributed Sampler....\n",
            "INFO 2021-01-25 20:27:27,291 __init__.py:  72: Distributed Sampler config:\n",
            "{'num_replicas': 1, 'rank': 0, 'epoch': 0, 'num_samples': 10, 'total_size': 10, 'shuffle': True}\n",
            "INFO 2021-01-25 20:27:27,292 __init__.py: 155: Wrapping the dataloader to async device copies\n",
            "INFO 2021-01-25 20:27:27,292 train_task.py: 419: Building model....\n",
            "INFO 2021-01-25 20:27:27,292 resnext.py:  63: ResNeXT trunk, supports activation checkpointing. Deactivated\n",
            "INFO 2021-01-25 20:27:27,292 resnext.py:  83: Building model: ResNeXt50-1x64d-w1-BatchNorm2d\n",
            "INFO 2021-01-25 20:27:27,953 train_task.py: 378: Initializing model from: /content/resnet50-19c8e357.pth\n",
            "INFO 2021-01-25 20:27:27,954 util.py: 277: Attempting to load checkpoint from /content/resnet50-19c8e357.pth\n",
            "INFO 2021-01-25 20:27:28,163 util.py: 282: Loaded checkpoint from /content/resnet50-19c8e357.pth\n",
            "INFO 2021-01-25 20:27:28,163 util.py: 241: Broadcasting checkpoint loaded from /content/resnet50-19c8e357.pth\n",
            "INFO 2021-01-25 20:27:30,934 checkpoint.py: 455: Loaded: trunk._feature_blocks.conv1.weight                              of shape: torch.Size([64, 3, 7, 7]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,934 checkpoint.py: 455: Loaded: trunk._feature_blocks.bn1.weight                                of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,935 checkpoint.py: 455: Loaded: trunk._feature_blocks.bn1.bias                                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,935 checkpoint.py: 455: Loaded: trunk._feature_blocks.bn1.running_mean                          of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,935 checkpoint.py: 455: Loaded: trunk._feature_blocks.bn1.running_var                           of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,935 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:27:30,935 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.0.conv1.weight                     of shape: torch.Size([64, 64, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,935 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.0.bn1.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,935 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.0.bn1.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,935 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.0.bn1.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,935 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.0.bn1.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,935 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer1.0.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:27:30,935 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.0.conv2.weight                     of shape: torch.Size([64, 64, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,936 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.0.bn2.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,936 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.0.bn2.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,936 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.0.bn2.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,936 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.0.bn2.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,936 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer1.0.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:27:30,936 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.0.conv3.weight                     of shape: torch.Size([256, 64, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,936 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.0.bn3.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,936 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.0.bn3.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,936 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.0.bn3.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,936 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.0.bn3.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,936 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer1.0.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:27:30,937 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.0.downsample.0.weight              of shape: torch.Size([256, 64, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,937 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.0.downsample.1.weight              of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,937 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.0.downsample.1.bias                of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,937 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.0.downsample.1.running_mean        of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,937 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.0.downsample.1.running_var         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,937 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer1.0.downsample.1.num_batches_tracked\n",
            "INFO 2021-01-25 20:27:30,937 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.1.conv1.weight                     of shape: torch.Size([64, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,937 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.1.bn1.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,937 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.1.bn1.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,937 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.1.bn1.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,937 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.1.bn1.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,937 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer1.1.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:27:30,938 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.1.conv2.weight                     of shape: torch.Size([64, 64, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,938 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.1.bn2.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,938 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.1.bn2.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,938 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.1.bn2.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,938 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.1.bn2.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,938 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer1.1.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:27:30,938 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.1.conv3.weight                     of shape: torch.Size([256, 64, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,938 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.1.bn3.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,938 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.1.bn3.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,938 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.1.bn3.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,938 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.1.bn3.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,939 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer1.1.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:27:30,939 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.2.conv1.weight                     of shape: torch.Size([64, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,939 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.2.bn1.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,939 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.2.bn1.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,939 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.2.bn1.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,939 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.2.bn1.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,939 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer1.2.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:27:30,939 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.2.conv2.weight                     of shape: torch.Size([64, 64, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,939 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.2.bn2.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,939 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.2.bn2.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,939 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.2.bn2.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,939 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.2.bn2.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,940 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer1.2.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:27:30,940 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.2.conv3.weight                     of shape: torch.Size([256, 64, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,940 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.2.bn3.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,940 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.2.bn3.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,940 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.2.bn3.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,940 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.2.bn3.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,940 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer1.2.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:27:30,940 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.0.conv1.weight                     of shape: torch.Size([128, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,940 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.0.bn1.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,940 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.0.bn1.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,940 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.0.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,941 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.0.bn1.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,941 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer2.0.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:27:30,941 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.0.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,941 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.0.bn2.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,941 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.0.bn2.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,941 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.0.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,941 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.0.bn2.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,941 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer2.0.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:27:30,941 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.0.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,941 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.0.bn3.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,942 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.0.bn3.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,942 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.0.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,942 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.0.bn3.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,942 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer2.0.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:27:30,942 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.0.downsample.0.weight              of shape: torch.Size([512, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,942 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.0.downsample.1.weight              of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,942 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.0.downsample.1.bias                of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,942 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.0.downsample.1.running_mean        of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,942 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.0.downsample.1.running_var         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,942 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer2.0.downsample.1.num_batches_tracked\n",
            "INFO 2021-01-25 20:27:30,943 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.1.conv1.weight                     of shape: torch.Size([128, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,943 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.1.bn1.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,943 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.1.bn1.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,943 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.1.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,943 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.1.bn1.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,943 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer2.1.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:27:30,943 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.1.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,943 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.1.bn2.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,943 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.1.bn2.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,944 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.1.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,944 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.1.bn2.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,944 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer2.1.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:27:30,944 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.1.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,944 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.1.bn3.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,944 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.1.bn3.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,944 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.1.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,944 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.1.bn3.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,944 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer2.1.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:27:30,944 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.2.conv1.weight                     of shape: torch.Size([128, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,944 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.2.bn1.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,945 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.2.bn1.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,945 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.2.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,945 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.2.bn1.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,945 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer2.2.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:27:30,945 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.2.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,945 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.2.bn2.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,945 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.2.bn2.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:27:30,945 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.2.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,002 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.2.bn2.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,002 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer2.2.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:27:31,002 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.2.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,002 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.2.bn3.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,002 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.2.bn3.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,002 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.2.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,003 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.2.bn3.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,003 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer2.2.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:27:31,003 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.3.conv1.weight                     of shape: torch.Size([128, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,003 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.3.bn1.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,003 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.3.bn1.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,003 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.3.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,003 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.3.bn1.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,003 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer2.3.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:27:31,004 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.3.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,004 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.3.bn2.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,004 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.3.bn2.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,004 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.3.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,004 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.3.bn2.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,004 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer2.3.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:27:31,005 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.3.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,005 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.3.bn3.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,005 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.3.bn3.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,005 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.3.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,005 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.3.bn3.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,005 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer2.3.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:27:31,005 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.0.conv1.weight                     of shape: torch.Size([256, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,006 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.0.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,006 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.0.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,006 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.0.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,006 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.0.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,006 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer3.0.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:27:31,007 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.0.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,007 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.0.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,007 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.0.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,007 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.0.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,007 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.0.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,007 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer3.0.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:27:31,007 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.0.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,008 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.0.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,008 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.0.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,008 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.0.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,008 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.0.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,008 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer3.0.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:27:31,008 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.0.downsample.0.weight              of shape: torch.Size([1024, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,008 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.0.downsample.1.weight              of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,009 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.0.downsample.1.bias                of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,009 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.0.downsample.1.running_mean        of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,009 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.0.downsample.1.running_var         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,009 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer3.0.downsample.1.num_batches_tracked\n",
            "INFO 2021-01-25 20:27:31,009 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.1.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,009 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.1.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,009 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.1.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,009 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.1.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,009 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.1.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,009 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer3.1.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:27:31,010 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.1.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,010 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.1.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,010 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.1.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,010 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.1.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,010 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.1.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,010 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer3.1.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:27:31,011 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.1.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,011 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.1.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,011 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.1.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,011 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.1.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,011 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.1.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,011 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer3.1.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:27:31,011 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.2.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,012 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.2.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,012 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.2.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,012 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.2.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,012 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.2.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,012 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer3.2.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:27:31,012 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.2.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,013 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.2.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,013 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.2.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,013 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.2.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,013 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.2.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,013 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer3.2.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:27:31,013 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.2.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,013 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.2.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,013 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.2.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,013 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.2.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,013 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.2.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,014 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer3.2.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:27:31,014 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.3.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,014 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.3.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,014 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.3.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,014 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.3.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,014 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.3.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,014 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer3.3.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:27:31,015 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.3.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,015 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.3.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,015 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.3.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,015 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.3.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,015 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.3.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,015 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer3.3.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:27:31,015 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.3.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,016 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.3.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,016 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.3.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,016 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.3.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,016 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.3.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,016 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer3.3.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:27:31,016 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.4.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,016 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.4.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,016 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.4.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,016 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.4.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,017 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.4.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,017 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer3.4.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:27:31,017 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.4.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,017 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.4.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,017 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.4.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,017 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.4.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,017 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.4.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,018 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer3.4.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:27:31,018 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.4.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,018 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.4.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,018 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.4.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,018 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.4.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,018 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.4.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,018 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer3.4.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:27:31,019 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.5.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,019 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.5.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,019 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.5.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,019 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.5.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,019 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.5.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,019 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer3.5.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:27:31,019 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.5.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,020 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.5.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,020 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.5.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,020 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.5.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,020 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.5.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,020 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer3.5.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:27:31,020 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.5.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,020 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.5.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,020 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.5.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,020 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.5.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,021 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.5.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,021 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer3.5.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:27:31,021 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.0.conv1.weight                     of shape: torch.Size([512, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,021 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.0.bn1.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,021 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.0.bn1.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,021 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.0.bn1.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,021 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.0.bn1.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,022 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer4.0.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:27:31,023 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.0.conv2.weight                     of shape: torch.Size([512, 512, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,023 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.0.bn2.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,023 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.0.bn2.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,023 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.0.bn2.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,107 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.0.bn2.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,107 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer4.0.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:27:31,108 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.0.conv3.weight                     of shape: torch.Size([2048, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,108 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.0.bn3.weight                       of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,108 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.0.bn3.bias                         of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,109 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.0.bn3.running_mean                 of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,109 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.0.bn3.running_var                  of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,109 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer4.0.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:27:31,110 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.0.downsample.0.weight              of shape: torch.Size([2048, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,111 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.0.downsample.1.weight              of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,111 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.0.downsample.1.bias                of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,111 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.0.downsample.1.running_mean        of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,111 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.0.downsample.1.running_var         of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,111 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer4.0.downsample.1.num_batches_tracked\n",
            "INFO 2021-01-25 20:27:31,112 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.1.conv1.weight                     of shape: torch.Size([512, 2048, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,112 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.1.bn1.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,112 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.1.bn1.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,112 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.1.bn1.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,112 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.1.bn1.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,112 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer4.1.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:27:31,114 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.1.conv2.weight                     of shape: torch.Size([512, 512, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,114 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.1.bn2.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,114 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.1.bn2.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,114 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.1.bn2.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,115 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.1.bn2.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,115 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer4.1.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:27:31,115 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.1.conv3.weight                     of shape: torch.Size([2048, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,116 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.1.bn3.weight                       of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,116 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.1.bn3.bias                         of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,116 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.1.bn3.running_mean                 of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,116 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.1.bn3.running_var                  of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,116 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer4.1.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:27:31,117 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.2.conv1.weight                     of shape: torch.Size([512, 2048, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,117 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.2.bn1.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,117 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.2.bn1.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,117 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.2.bn1.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,117 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.2.bn1.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,117 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer4.2.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:27:31,119 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.2.conv2.weight                     of shape: torch.Size([512, 512, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,119 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.2.bn2.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,119 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.2.bn2.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,119 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.2.bn2.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,120 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.2.bn2.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,120 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer4.2.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:27:31,120 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.2.conv3.weight                     of shape: torch.Size([2048, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,121 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.2.bn3.weight                       of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,121 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.2.bn3.bias                         of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,121 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.2.bn3.running_mean                 of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,121 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.2.bn3.running_var                  of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:27:31,121 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer4.2.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:27:31,121 checkpoint.py: 463: Not found:\t\theads.0.clf.0.weight, not initialized\n",
            "INFO 2021-01-25 20:27:31,121 checkpoint.py: 463: Not found:\t\theads.0.clf.0.bias, not initialized\n",
            "INFO 2021-01-25 20:27:31,121 checkpoint.py: 470: Extra layers not loaded from checkpoint: ['trunk._feature_blocks.fc.weight', 'trunk._feature_blocks.fc.bias']\n",
            "INFO 2021-01-25 20:27:31,127 train_task.py: 591: Broadcast model BN buffers from master on every forward pass\n",
            "INFO 2021-01-25 20:27:31,127 classification_task.py: 359: Synchronized Batch Normalization is disabled\n",
            "INFO 2021-01-25 20:27:31,127 train_task.py: 340: Building loss...\n",
            "INFO 2021-01-25 20:27:31,175 optimizer_helper.py: 157: \n",
            "Trainable params: 161, \n",
            "Non-Trainable params: 0, \n",
            "Trunk Regularized Parameters: 53, \n",
            "Trunk Unregularized Parameters 106, \n",
            "Head Regularized Parameters: 2, \n",
            "Head Unregularized Parameters: 0 \n",
            "Remaining Regularized Parameters: 0 \n",
            "INFO 2021-01-25 20:27:31,175 trainer_main.py: 241: Training 2 epochs. One epoch = 5 iterations\n",
            "INFO 2021-01-25 20:27:31,175 trainer_main.py: 243: Total 10 iterations for training\n",
            "INFO 2021-01-25 20:27:31,175 trainer_main.py: 244: Total 10 samples in one epoch\n",
            "INFO 2021-01-25 20:27:31,330 logger.py:  76: Mon Jan 25 20:27:31 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P0    26W /  70W |    915MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "\n",
            "INFO 2021-01-25 20:27:31,332 trainer_main.py: 166: Model is:\n",
            " Classy <class 'vissl.models.base_ssl_model.BaseSSLMultiInputOutputModel'>:\n",
            "BaseSSLMultiInputOutputModel(\n",
            "  (_heads): ModuleDict()\n",
            "  (trunk): ResNeXt(\n",
            "    (_feature_blocks): ModuleDict(\n",
            "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv1_relu): ReLU(inplace=True)\n",
            "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "      (layer1): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (layer2): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (3): Bottleneck(\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (layer3): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (3): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (4): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (5): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (layer4): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(<SUPPORTED_L4_STRIDE.two: 2>, <SUPPORTED_L4_STRIDE.two: 2>), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(<SUPPORTED_L4_STRIDE.two: 2>, <SUPPORTED_L4_STRIDE.two: 2>), bias=False)\n",
            "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "      (flatten): Flatten()\n",
            "    )\n",
            "  )\n",
            "  (heads): ModuleList(\n",
            "    (0): MLP(\n",
            "      (clf): Sequential(\n",
            "        (0): Linear(in_features=2048, out_features=1000, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "INFO 2021-01-25 20:27:31,416 trainer_main.py: 167: Loss is: CrossEntropyMultipleOutputSingleTargetLoss(\n",
            "  (_losses): ModuleList()\n",
            ")\n",
            "INFO 2021-01-25 20:27:31,416 trainer_main.py: 168: Starting training....\n",
            "INFO 2021-01-25 20:27:31,417 __init__.py:  72: Distributed Sampler config:\n",
            "{'num_replicas': 1, 'rank': 0, 'epoch': 0, 'num_samples': 10, 'total_size': 10, 'shuffle': True}\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "INFO 2021-01-25 20:27:37,753 trainer_main.py: 296: Phase advanced. Rank: 0\n",
            "INFO 2021-01-25 20:27:37,753 state_update_hooks.py:  98: Starting phase 0 [train]\n",
            "INFO 2021-01-25 20:27:38,653 log_hooks.py: 155: Rank: 0; [ep: 0] iter: 1; lr: 0.00078; loss: 6.67293; btime(ms): 7477; eta: 0:01:07; peak_mem: 2595M\n",
            "INFO 2021-01-25 20:27:38,826 log_hooks.py: 155: Rank: 0; [ep: 0] iter: 5; lr: 0.00078; loss: 4.55565; btime(ms): 1528; eta: 0:00:07; peak_mem: 2595M\n",
            "INFO 2021-01-25 20:27:38,827 trainer_main.py: 194: Meters synced\n",
            "INFO 2021-01-25 20:27:38,855 log_hooks.py: 416: Average train batch time (ms) for 5 batches: 220\n",
            "INFO 2021-01-25 20:27:38,855 log_hooks.py: 425: Train step time breakdown (rank 0):\n",
            "               Timer     Host    CudaEvent\n",
            "         read_sample:    3.89 ms    2.04 ms\n",
            "             forward:   99.69 ms   98.72 ms\n",
            "        loss_compute:    2.93 ms    2.93 ms\n",
            "     loss_all_reduce:    0.07 ms    0.07 ms\n",
            "       meters_update:    9.82 ms    9.84 ms\n",
            "            backward:   81.14 ms   88.66 ms\n",
            "      optimizer_step:    8.14 ms    6.47 ms\n",
            "    train_step_total:  213.48 ms  213.56 ms\n",
            "INFO 2021-01-25 20:27:38,855 log_hooks.py: 346: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {0: 30.0}, 'top_5': {0: 60.0}}\n",
            "INFO 2021-01-25 20:27:38,855 io.py:  56: Saving data to file: ./checkpoints/metrics.json\n",
            "INFO 2021-01-25 20:27:38,856 io.py:  70: Saved data to file: ./checkpoints/metrics.json\n",
            "INFO 2021-01-25 20:27:38,856 log_hooks.py: 283: [phase: 0] Saving checkpoint to ./checkpoints\n",
            "INFO 2021-01-25 20:27:39,210 log_hooks.py: 312: Saved checkpoint: ./checkpoints/model_phase0.torch\n",
            "INFO 2021-01-25 20:27:39,210 log_hooks.py: 316: Creating symlink...\n",
            "INFO 2021-01-25 20:27:39,211 log_hooks.py: 320: Created symlink: ./checkpoints/checkpoint.torch\n",
            "INFO 2021-01-25 20:27:39,211 __init__.py:  72: Distributed Sampler config:\n",
            "{'num_replicas': 1, 'rank': 0, 'epoch': 1, 'num_samples': 10, 'total_size': 10, 'shuffle': True}\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "INFO 2021-01-25 20:27:45,044 trainer_main.py: 296: Phase advanced. Rank: 0\n",
            "INFO 2021-01-25 20:27:45,044 state_update_hooks.py:  98: Starting phase 1 [test]\n",
            "INFO 2021-01-25 20:27:45,361 trainer_main.py: 194: Meters synced\n",
            "INFO 2021-01-25 20:27:45,361 log_hooks.py: 416: Average test batch time (ms) for 5 batches: 63\n",
            "INFO 2021-01-25 20:27:45,362 log_hooks.py: 346: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {0: 50.0}, 'top_5': {0: 100.0}}\n",
            "INFO 2021-01-25 20:27:45,362 io.py:  56: Saving data to file: ./checkpoints/metrics.json\n",
            "INFO 2021-01-25 20:27:45,362 io.py:  70: Saved data to file: ./checkpoints/metrics.json\n",
            "INFO 2021-01-25 20:27:45,362 __init__.py:  72: Distributed Sampler config:\n",
            "{'num_replicas': 1, 'rank': 0, 'epoch': 2, 'num_samples': 10, 'total_size': 10, 'shuffle': True}\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "INFO 2021-01-25 20:27:50,928 trainer_main.py: 296: Phase advanced. Rank: 0\n",
            "INFO 2021-01-25 20:27:50,928 state_update_hooks.py:  98: Starting phase 2 [train]\n",
            "INFO 2021-01-25 20:27:51,596 log_hooks.py: 155: Rank: 0; [ep: 1] iter: 10; lr: 8e-05; loss: 3.35044; btime(ms): 1360; eta: 0:00:00; peak_mem: 2595M\n",
            "INFO 2021-01-25 20:27:51,597 trainer_main.py: 194: Meters synced\n",
            "INFO 2021-01-25 20:27:51,597 log_hooks.py: 416: Average train batch time (ms) for 5 batches: 133\n",
            "INFO 2021-01-25 20:27:51,597 log_hooks.py: 425: Train step time breakdown (rank 0):\n",
            "               Timer     Host    CudaEvent\n",
            "         read_sample:   64.66 ms   60.52 ms\n",
            "             forward:   23.65 ms   24.22 ms\n",
            "        loss_compute:    0.43 ms    0.44 ms\n",
            "     loss_all_reduce:    0.10 ms    0.10 ms\n",
            "       meters_update:    0.46 ms    0.48 ms\n",
            "            backward:   21.46 ms   39.62 ms\n",
            "      optimizer_step:   11.42 ms    6.05 ms\n",
            "    train_step_total:  132.10 ms  132.21 ms\n",
            "INFO 2021-01-25 20:27:51,598 log_hooks.py: 346: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {0: 50.0}, 'top_5': {0: 100.0}}\n",
            "INFO 2021-01-25 20:27:51,598 io.py:  56: Saving data to file: ./checkpoints/metrics.json\n",
            "INFO 2021-01-25 20:27:51,598 io.py:  70: Saved data to file: ./checkpoints/metrics.json\n",
            "INFO 2021-01-25 20:27:51,598 log_hooks.py: 283: [phase: 2] Saving checkpoint to ./checkpoints\n",
            "INFO 2021-01-25 20:27:51,921 log_hooks.py: 312: Saved checkpoint: ./checkpoints/model_final_checkpoint_phase2.torch\n",
            "INFO 2021-01-25 20:27:51,921 log_hooks.py: 316: Creating symlink...\n",
            "Error in symlink - [Errno 17] File exists: './checkpoints/model_final_checkpoint_phase2.torch' -> './checkpoints/checkpoint.torch'\n",
            "INFO 2021-01-25 20:27:51,921 log_hooks.py: 320: Created symlink: ./checkpoints/checkpoint.torch\n",
            "INFO 2021-01-25 20:27:51,922 __init__.py:  72: Distributed Sampler config:\n",
            "{'num_replicas': 1, 'rank': 0, 'epoch': 3, 'num_samples': 10, 'total_size': 10, 'shuffle': True}\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "INFO 2021-01-25 20:27:58,051 trainer_main.py: 296: Phase advanced. Rank: 0\n",
            "INFO 2021-01-25 20:27:58,051 state_update_hooks.py:  98: Starting phase 3 [test]\n",
            "INFO 2021-01-25 20:27:58,160 trainer_main.py: 194: Meters synced\n",
            "INFO 2021-01-25 20:27:58,161 log_hooks.py: 416: Average test batch time (ms) for 5 batches: 21\n",
            "INFO 2021-01-25 20:27:58,161 log_hooks.py: 346: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {0: 50.0}, 'top_5': {0: 100.0}}\n",
            "INFO 2021-01-25 20:27:58,161 io.py:  56: Saving data to file: ./checkpoints/metrics.json\n",
            "INFO 2021-01-25 20:27:58,161 io.py:  70: Saved data to file: ./checkpoints/metrics.json\n",
            "INFO 2021-01-25 20:27:58,237 train.py: 103: All Done!\n",
            "INFO 2021-01-25 20:27:58,237 logger.py:  66: Shutting down loggers...\n",
            "INFO 2021-01-25 20:27:58,237 run_distributed_engines.py: 133: All Done!\n",
            "INFO 2021-01-25 20:27:58,237 logger.py:  66: Shutting down loggers...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8fILq7VzyOu"
      },
      "source": [
        "And we are done!! We have the full-finetuned model and the `metrics.json` containing `top-1` and `top-5` accuracy on validation set is available in `checkpoints/metrics.json`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otUmgl4ms96M",
        "outputId": "ff3b39df-f024-48c0-fbed-3589f45b20ad"
      },
      "source": [
        "ls checkpoints/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;36mcheckpoint.torch\u001b[0m@  metrics.json                         model_phase0.torch\n",
            "log.txt            model_final_checkpoint_phase2.torch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDMLjudpya2I",
        "outputId": "65ab71d0-a48a-423e-b15d-292a268cf2f9"
      },
      "source": [
        "cat checkpoints/metrics.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\"iteration\": 5, \"phase_idx\": 0, \"train_accuracy_list_meter\": {\"top_1\": {\"0\": 30.0}, \"top_5\": {\"0\": 60.0}}, \"train_phase_idx\": 0}\n",
            "{\"iteration\": 5, \"phase_idx\": 1, \"test_accuracy_list_meter\": {\"top_1\": {\"0\": 50.0}, \"top_5\": {\"0\": 100.0}}, \"train_phase_idx\": 0}\n",
            "{\"iteration\": 10, \"phase_idx\": 2, \"train_accuracy_list_meter\": {\"top_1\": {\"0\": 50.0}, \"top_5\": {\"0\": 100.0}}, \"train_phase_idx\": 1}\n",
            "{\"iteration\": 10, \"phase_idx\": 3, \"test_accuracy_list_meter\": {\"top_1\": {\"0\": 50.0}, \"top_5\": {\"0\": 100.0}}, \"train_phase_idx\": 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xFUcTj00B_a"
      },
      "source": [
        "# Loading Pre-trained models in VISSL\n",
        "\n",
        "VISSL supports Torchvision models out of the box. Generally, for loading any non-VISSL model, one needs to correctly set the following configuration options:\n",
        "\n",
        "```yaml\n",
        "WEIGHTS_INIT:\n",
        "  # path to the .torch weights files\n",
        "  PARAMS_FILE: \"\"\n",
        "  # name of the state dict. checkpoint = {\"classy_state_dict\": {layername:value}}. Options:\n",
        "  #   1. classy_state_dict - if model is trained and checkpointed with VISSL.\n",
        "  #      checkpoint = {\"classy_state_dict\": {layername:value}}\n",
        "  #   2. \"\" - if the model_file is not a nested dictionary for model weights i.e.\n",
        "  #      checkpoint = {layername:value}\n",
        "  #   3. key name that your model checkpoint uses for state_dict key name.\n",
        "  #      checkpoint = {\"your_key_name\": {layername:value}}\n",
        "  STATE_DICT_KEY_NAME: \"classy_state_dict\"\n",
        "  # specify what layer should not be loaded. Layer names with this key are not copied\n",
        "  # By default, set to BatchNorm stats \"num_batches_tracked\" to be skipped.\n",
        "  SKIP_LAYERS: [\"num_batches_tracked\"]\n",
        "  ####### If loading a non-VISSL trained model, set the following two args carefully #########\n",
        "  # to make the checkpoint compatible with VISSL, if you need to remove some names\n",
        "  # from the checkpoint keys, specify the name\n",
        "  REMOVE_PREFIX: \"\"\n",
        "  # In order to load the model (if not trained with VISSL) with VISSL, there are 2 scenarios:\n",
        "  #    1. If you are interested in evaluating the model features and freeze the trunk.\n",
        "  #       Set APPEND_PREFIX=\"trunk.base_model.\" This assumes that your model is compatible\n",
        "  #       with the VISSL trunks. The VISSL trunks start with \"_feature_blocks.\" prefix. If\n",
        "  #       your model doesn't have these prefix you can append them. For example:\n",
        "  #       For TorchVision ResNet trunk, set APPEND_PREFIX=\"trunk.base_model._feature_blocks.\"\n",
        "  #    2. where you want to load the model simply and finetune the full model.\n",
        "  #       Set APPEND_PREFIX=\"trunk.\"\n",
        "  #       This assumes that your model is compatible with the VISSL trunks. The VISSL\n",
        "  #       trunks start with \"_feature_blocks.\" prefix. If your model doesn't have these\n",
        "  #       prefix you can append them.\n",
        "  #       For TorchVision ResNet trunk, set APPEND_PREFIX=\"trunk._feature_blocks.\"\n",
        "  # NOTE: the prefix is appended to all the layers in the model\n",
        "  APPEND_PREFIX: \"\"\n",
        "  ```"
      ]
    }
  ]
}